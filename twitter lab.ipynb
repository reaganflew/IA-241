{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "import tweepy\n",
    "import twitter\n",
    "from pprint import pprint\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mongodb+srv://demo_user:Serlexers123@cluster0-oawp1.mongodb.net/test?retryWrites=true&w=majority\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "CONSUMER_KEY      = config['mytwitter']['api_key']\n",
    "CONSUMER_SECRET   = config['mytwitter']['api_secrete']\n",
    "OAUTH_TOKEN       = config['mytwitter']['access_token']\n",
    "OATH_TOKEN_SECRET = config['mytwitter']['access_secrete']\n",
    "\n",
    "mongod_connect = config['mymongo']['connection']\n",
    "print(mongod_connect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id_1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient(mongod_connect)\n",
    "db = client.tweet_db # create a database named tweet_db\n",
    "tweet_collection = db.tweet_collection_job\n",
    "#create a collection called tweet_collection\n",
    "tweet_collection.create_index([(\"id\", pymongo.ASCENDING)],unique = True) # make sure the collected tweets are unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "stream_auth.set_access_token(OAUTH_TOKEN, OATH_TOKEN_SECRET)\n",
    "\n",
    "strem_api = tweepy.API(stream_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track = ['IAJobs'] # define the keywords, tweets contain JMU\n",
    "\n",
    "#locations = [-78.9326449,38.4150904,-78.8816972,38.4450731] #defin the location, in Harrisonburg, VA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    def on_status(self, status):\n",
    "        print (status.id_str)\n",
    "        try:\n",
    "            tweet_collection.insert_one(status._json)\n",
    "        except:\n",
    "            pass\n",
    "  \n",
    "    def on_error(self, status_code):\n",
    "        if status_code == 420:\n",
    "            #returning False in on_data disconnects the stream\n",
    "            return False\n",
    "myStreamListener = MyStreamListener()\n",
    "myStream = tweepy.Stream(auth = strem_api.auth, listener=myStreamListener)\n",
    "myStream.filter(track=track)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweet_collection.estimated_document_count())# number of tweets collected\n",
    "\n",
    "user_cursor = tweet_collection.distinct(\"user.id\")\n",
    "print (len(user_cursor)) # number of unique Twitter users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rest_auth = twitter.oauth.OAuth(OAUTH_TOKEN,OATH_TOKEN_SECRET,CONSUMER_KEY,CONSUMER_SECRET)\n",
    "rest_api = twitter.Twitter(auth=rest_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count = 10 #number of returned tweets, default and max is 100\n",
    "#geocode = \"38.4392897,-78.9412224,50mi\"  # defin the location, in Harrisonburg, VA\n",
    "q = \"ia job\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Tue Nov 05 20:05:34 +0000 2019'\n",
      "'Tue Nov 05 20:01:45 +0000 2019'\n",
      "'Tue Nov 05 20:01:36 +0000 2019'\n",
      "'Tue Nov 05 19:56:34 +0000 2019'\n",
      "'Tue Nov 05 19:55:54 +0000 2019'\n",
      "'Tue Nov 05 19:55:13 +0000 2019'\n",
      "'Tue Nov 05 19:54:54 +0000 2019'\n",
      "'Tue Nov 05 19:54:43 +0000 2019'\n",
      "'Tue Nov 05 19:50:34 +0000 2019'\n",
      "'Tue Nov 05 19:50:24 +0000 2019'\n"
     ]
    }
   ],
   "source": [
    "search_results = rest_api.search.tweets( count=count,q=q)\n",
    "statuses = search_results[\"statuses\"]\n",
    "since_id_new = statuses[-1]['id']\n",
    "for statuse in statuses:\n",
    "    try:\n",
    "        tweet_collection.insert_one(statuse)\n",
    "        pprint(statuse['created_at'])# print the date of the collected tweets\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Tue Nov 05 19:49:57 +0000 2019'\n",
      "'Tue Nov 05 19:48:43 +0000 2019'\n",
      "'Tue Nov 05 19:46:52 +0000 2019'\n",
      "'Tue Nov 05 19:46:43 +0000 2019'\n",
      "'Tue Nov 05 19:46:18 +0000 2019'\n",
      "'Tue Nov 05 19:45:33 +0000 2019'\n",
      "'Tue Nov 05 19:45:13 +0000 2019'\n",
      "'Tue Nov 05 19:44:52 +0000 2019'\n",
      "'Tue Nov 05 19:44:23 +0000 2019'\n",
      "'Tue Nov 05 19:42:21 +0000 2019'\n",
      "'Tue Nov 05 19:39:12 +0000 2019'\n",
      "'Tue Nov 05 19:38:32 +0000 2019'\n",
      "'Tue Nov 05 19:37:22 +0000 2019'\n",
      "'Tue Nov 05 19:30:41 +0000 2019'\n",
      "'Tue Nov 05 19:29:21 +0000 2019'\n",
      "'Tue Nov 05 19:28:53 +0000 2019'\n",
      "'Tue Nov 05 19:28:22 +0000 2019'\n",
      "'Tue Nov 05 19:27:20 +0000 2019'\n",
      "'Tue Nov 05 19:25:30 +0000 2019'\n",
      "'Tue Nov 05 19:24:02 +0000 2019'\n",
      "'Tue Nov 05 19:23:37 +0000 2019'\n",
      "'Tue Nov 05 19:20:40 +0000 2019'\n",
      "'Tue Nov 05 19:19:50 +0000 2019'\n",
      "'Tue Nov 05 19:16:30 +0000 2019'\n",
      "'Tue Nov 05 19:15:39 +0000 2019'\n",
      "'Tue Nov 05 19:12:11 +0000 2019'\n",
      "'Tue Nov 05 19:10:39 +0000 2019'\n",
      "'Tue Nov 05 19:08:09 +0000 2019'\n",
      "'Tue Nov 05 19:07:29 +0000 2019'\n",
      "'Tue Nov 05 19:07:19 +0000 2019'\n",
      "'Tue Nov 05 19:05:29 +0000 2019'\n",
      "'Tue Nov 05 19:03:28 +0000 2019'\n",
      "'Tue Nov 05 19:02:52 +0000 2019'\n",
      "'Tue Nov 05 19:00:28 +0000 2019'\n",
      "'Tue Nov 05 18:49:17 +0000 2019'\n",
      "'Tue Nov 05 18:48:27 +0000 2019'\n",
      "'Tue Nov 05 18:47:47 +0000 2019'\n",
      "'Tue Nov 05 18:47:27 +0000 2019'\n",
      "'Tue Nov 05 18:45:26 +0000 2019'\n",
      "'Tue Nov 05 18:44:38 +0000 2019'\n",
      "'Tue Nov 05 18:43:26 +0000 2019'\n",
      "'Tue Nov 05 18:38:18 +0000 2019'\n",
      "'Tue Nov 05 18:37:55 +0000 2019'\n",
      "'Tue Nov 05 18:37:15 +0000 2019'\n",
      "'Tue Nov 05 18:31:15 +0000 2019'\n",
      "'Tue Nov 05 18:27:54 +0000 2019'\n",
      "'Tue Nov 05 18:23:44 +0000 2019'\n",
      "'Tue Nov 05 18:21:05 +0000 2019'\n",
      "'Tue Nov 05 18:20:46 +0000 2019'\n",
      "'Tue Nov 05 18:19:53 +0000 2019'\n",
      "'Tue Nov 05 18:18:14 +0000 2019'\n",
      "'Tue Nov 05 18:17:55 +0000 2019'\n",
      "'Tue Nov 05 18:16:25 +0000 2019'\n",
      "'Tue Nov 05 18:14:00 +0000 2019'\n",
      "'Tue Nov 05 18:11:10 +0000 2019'\n",
      "'Tue Nov 05 18:09:13 +0000 2019'\n",
      "'Tue Nov 05 18:07:43 +0000 2019'\n",
      "'Tue Nov 05 18:06:32 +0000 2019'\n",
      "'Tue Nov 05 18:05:04 +0000 2019'\n",
      "'Tue Nov 05 18:04:34 +0000 2019'\n",
      "'Tue Nov 05 18:03:12 +0000 2019'\n",
      "'Tue Nov 05 18:02:02 +0000 2019'\n",
      "'Tue Nov 05 18:01:03 +0000 2019'\n",
      "'Tue Nov 05 18:01:01 +0000 2019'\n",
      "'Tue Nov 05 17:55:11 +0000 2019'\n",
      "'Tue Nov 05 17:53:33 +0000 2019'\n",
      "'Tue Nov 05 17:53:20 +0000 2019'\n",
      "'Tue Nov 05 17:45:09 +0000 2019'\n",
      "'Tue Nov 05 17:41:20 +0000 2019'\n",
      "'Tue Nov 05 17:40:50 +0000 2019'\n",
      "'Tue Nov 05 17:40:32 +0000 2019'\n",
      "'Tue Nov 05 17:39:01 +0000 2019'\n",
      "'Tue Nov 05 17:37:09 +0000 2019'\n",
      "'Tue Nov 05 17:33:08 +0000 2019'\n",
      "'Tue Nov 05 17:31:39 +0000 2019'\n",
      "'Tue Nov 05 17:30:43 +0000 2019'\n",
      "'Tue Nov 05 17:30:40 +0000 2019'\n",
      "'Tue Nov 05 17:30:38 +0000 2019'\n",
      "'Tue Nov 05 17:29:30 +0000 2019'\n",
      "'Tue Nov 05 17:29:11 +0000 2019'\n",
      "'Tue Nov 05 17:27:30 +0000 2019'\n",
      "'Tue Nov 05 17:27:09 +0000 2019'\n",
      "'Tue Nov 05 17:23:18 +0000 2019'\n",
      "'Tue Nov 05 17:20:57 +0000 2019'\n",
      "'Tue Nov 05 17:18:16 +0000 2019'\n",
      "'Tue Nov 05 17:16:57 +0000 2019'\n",
      "'Tue Nov 05 17:16:46 +0000 2019'\n",
      "'Tue Nov 05 17:15:24 +0000 2019'\n",
      "'Tue Nov 05 17:13:51 +0000 2019'\n",
      "'Tue Nov 05 17:13:06 +0000 2019'\n",
      "'Tue Nov 05 17:10:17 +0000 2019'\n",
      "'Tue Nov 05 17:08:46 +0000 2019'\n",
      "'Tue Nov 05 17:06:47 +0000 2019'\n",
      "'Tue Nov 05 17:02:58 +0000 2019'\n",
      "'Tue Nov 05 17:01:56 +0000 2019'\n",
      "'Tue Nov 05 17:00:49 +0000 2019'\n",
      "'Tue Nov 05 16:59:55 +0000 2019'\n",
      "'Tue Nov 05 16:59:35 +0000 2019'\n",
      "'Tue Nov 05 16:58:06 +0000 2019'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-b4add5773ccf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0msince_id_old\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msince_id_new\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     search_results = rest_api.search.tweets( count=count,q=q,\n\u001b[1;32m----> 5\u001b[1;33m                         max_id= since_id_new)\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mstatuses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"statuses\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0msince_id_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstatuses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\twitter\\api.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_response_with_retry\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_timeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\twitter\\api.py\u001b[0m in \u001b[0;36m_handle_response\u001b[1;34m(self, req, uri, arg_data, _timeout)\u001b[0m\n\u001b[0;32m    343\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mhttp_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncompleteRead\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m                 \u001b[1;31m# Even if we don't get all the bytes we should have there\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    460\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m                     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_close_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    610\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             \u001b[0mchunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1007\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1009\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1010\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1011\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    869\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    872\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    629\u001b[0m         \"\"\"\n\u001b[0;32m    630\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 631\u001b[1;33m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    632\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "since_id_old = 0\n",
    "while(since_id_new != since_id_old):\n",
    "    since_id_old = since_id_new\n",
    "    search_results = rest_api.search.tweets( count=count,q=q,\n",
    "                        max_id= since_id_new)\n",
    "    statuses = search_results[\"statuses\"]\n",
    "    since_id_new = statuses[-1]['id']\n",
    "    for statuse in statuses:\n",
    "        try:\n",
    "            tweet_collection.insert_one(statuse)\n",
    "            pprint(statuse['created_at']) # print the date of the collected tweets\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(tweet_collection.estimated_document_count())# number of tweets collected\n",
    "\n",
    "user_cursor = tweet_collection.distinct(\"user.id\")\n",
    "print (len(user_cursor)) # number of unique Twitter users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "name: TMJ-IAD Jobs\n",
      "text: Cognizant is looking for teammates like you. See our latest #BusinessMgmt job openings, including \"Data Entry Clerkâ€¦ https://t.co/5WHRWYM6j0\n"
     ]
    }
   ],
   "source": [
    "tweet_collection.create_index([(\"text\", pymongo.TEXT)], name='text_index', default_language='english') # create a text index\n",
    "\n",
    "tweet_cursor = tweet_collection.find({\"$text\": {\"$search\": \"data mining\"}}) # return tweets contain football\n",
    "for document in tweet_cursor:\n",
    "    try:\n",
    "        print ('----')\n",
    "#         pprint (document) # use pprint to print the entire tweet document\n",
    "   \n",
    "        print ('name:', document[\"user\"][\"name\"]) # user name\n",
    "        print ('text:', document[\"text\"])         # tweets\n",
    "    except:\n",
    "        print (\"***error in encoding\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
